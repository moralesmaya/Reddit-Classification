{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Sub-Reddit Classification \n",
    "\n",
    "\n",
    "\n",
    "### Problem Statement\n",
    "Can we build a model that can accurately differentiate between Men's Rights and Feminism subreddits? \n",
    "\n",
    "### Executive Summary\n",
    "\n",
    "The process began with requesting and importing data from each respective subreddit.Using a for-loop 2500 posts were obtained from r/MensRights and 2500 posts were obtained from r/Feminism. Of the information only text, title, and number of commments was kept for further analysis. \n",
    "\n",
    "2,805 out of 5000 text posts were missing from the dataset. This is probably because many reddit posts are just photos or links to other content. Due to the lack of missing values in the title column, title was used as our feature variable. \n",
    "\n",
    "After the data preparation, several basic manipulations we used to get a high-level understanding of the trends in the data. The data was analyzed for agression and hate-speech using Lexicon Profane Words. Further information about the dataset can be found here http://wiki.knoesis.org/index.php/Context-Aware_Harassment_Detection_on_Social_Media. \n",
    "\n",
    "More profane posts were found among the mens rights community than the feminism community however, not by much. MensRights had 248 posts classified as profane, Feminism had 249. In addition to prfane word analysis, general word analysis was also completed. Both communties had high frequencies of words relating to gender, such as \"men\", \"women\", they also contained words in relation to assault such as \"rape\" frequently. \n",
    "\n",
    "Further analysis was conducted to see how each community discussed assault. When feminism discusses assault, it is in conjunction with words like \"court\", \"culture\", \"abuse\", \"murder\", and \"virginity\". Whereas when the  men’s rights activists  talk about assault it more commonly comes with words such as \"drunk\", \"false\", \"accused\", \"falsely\", and \"allegations\". \n",
    "\n",
    "After starting to classify the models, our scores showed severe overfitting. After hypertuning parameters and running 20 classification models with either Count Vectorizer or TFIDF vectorizer the highest score was 70% for both train and test and was achieved by a SVC + TFIDF model. \n",
    "\n",
    "Of the 750 predictions made, 223 were misclassified. Many of these misclassifications were caused by broad and vague text such as  “Any good book recommendations?”. Posts like these could come from either community and woud be difficult to differetiate between. \n",
    "\n",
    "\n",
    "## Data Dictionary:\n",
    "\n",
    "\n",
    "Column  | Description\n",
    "  -------------  | -------------\n",
    "  text | The text in the reddit post\n",
    "  title | Title of the reddit post\n",
    "  num_comments | Number of comments on the given reddit post\n",
    "  target | 0 if the post came from r/MensRights, 1 if i came from r/Feminism\n",
    "\n",
    "\n",
    "\n",
    "## Future Reccomendations\n",
    "Based on the data analysis, there are a few recommendations to better improve classification models.\n",
    "\n",
    "- Retrieve more data point \n",
    "- Hypertune parameters further \n",
    "- Use text of post instead of title.\n",
    "- Combine text and title for a new feature. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
